use std::collections::{BTreeMap, BTreeSet};
use std::path::{Path, PathBuf};

use cu::pre::*;
use itertools::Itertools as _;
use pm::pre::*;

pub fn build_registry(crate_path: &Path) -> cu::Result<()> {
    let packages_path = {
        let mut p = crate_path.normalize()?;
        p.extend(["src", "packages"]);
        p
    };
    println!("cargo::rerun-if-changed={}", packages_path.as_utf8()?);
    let registry_path = packages_path.parent_abs()?;
    let output_path = registry_path.join("packages.gen.rs");

    let mut generator = RegistryGenerator::new(registry_path);

    for entry in cu::fs::read_dir(&packages_path)? {
        let entry = entry?;
        let file_name = entry.file_name();
        let name = cu::check!(
            file_name.to_str(),
            "file name is not utf-8: {}",
            file_name.display()
        )?;
        let (module_path, module_name) = if entry.file_type()?.is_dir() {
            let mut p = entry.path();
            p.push("mod.rs");
            (p, name)
        } else if let Some(name) = name.strip_suffix(".rs") {
            (entry.path(), name)
        } else {
            cu::bail!("invalid package structure at: '{}'", entry.path().display());
        };
        if !is_kebab(module_name) {
            println!("cargo::error='{module_name}' should be kebab case");
        }
        generator.add_package(module_path, module_name.to_string())?;
    }

    let output = generator.generate()?;
    cu::fs::write(output_path, output)?;

    Ok(())
}

struct RegistryGenerator {
    registry_path: PathBuf,
    modules: BTreeMap<String, PathBuf>,
}
impl RegistryGenerator {
    fn new(path: PathBuf) -> Self {
        Self {
            registry_path: path,
            modules: Default::default(),
        }
    }
    /// Generate code for a package
    fn add_package(&mut self, module_path: PathBuf, module_name: String) -> cu::Result<()> {
        if let Some(old) = self.modules.insert(module_name, module_path) {
            cu::bail!("conflict package found '{}'", old.display());
        }
        Ok(())
    }

    fn generate(self) -> cu::Result<String> {
        use std::fmt::Write as _;

        let mut out =
            "// This file is generated by the build script, do not edit manually.\n\n".to_string();
        writeln!(out, "use enumset::{{EnumSetType, EnumSet, enum_set}};")?;
        writeln!(out, "use enum_map::Enum;")?;
        writeln!(out, "#[path = \"./package_stub.rs\"]mod _stub;")?;

        // if the package name contains invalid character,
        // there will be build error in the generated code.
        // the name is not validated here
        // (it should be rare since the registry is fully controlled by me)

        let kebab_pkgs = self.modules.keys().collect::<Vec<_>>();
        let (pascal_pkgs, snake_pkgs) = generate_casings_from_kebab(&kebab_pkgs);
        cu::check!(
            generate_id_enum(&mut out, "Pkg", &kebab_pkgs, &pascal_pkgs),
            "failed to generate PkgId enum"
        )?;

        let mut all_binaries = BTreeSet::default();
        let mut modules = Vec::with_capacity(kebab_pkgs.len());

        for (key, path) in &self.modules {
            let m = cu::check!(
                GeneratedModule::try_from_path(path),
                "failed to parse module '{key}'"
            )?;
            all_binaries.extend(m.kebab_binaries.iter().cloned());
            modules.push(m);
        }

        let kebab_bins = all_binaries.iter().collect::<Vec<_>>();
        let (pascal_bins, _) = generate_casings_from_kebab(&kebab_bins);
        cu::check!(
            generate_id_enum(&mut out, "Bin", &kebab_bins, &pascal_bins),
            "failed to generate BinId enum"
        )?;

        // metadata table
        writeln!(
            out,
            "static METADATA_ARRAY: [crate::Package; <PkgId as Enum>::LENGTH] = ["
        )?;
        for (snake_name, (kebab_name, metadata)) in
            std::iter::zip(&snake_pkgs, std::iter::zip(&kebab_pkgs, &modules))
        {
            writeln!(out, "    crate::Package {{")?;
            writeln!(out, "        name: \"{kebab_name}\",")?;

            let binaries = metadata
                .kebab_binaries
                .iter()
                .map(|x| format!("BinId::{}", kebab_to_pascal(x)))
                .join(" | ");
            writeln!(out, "        binaries: enum_set!{{ {binaries} }},")?;

            if metadata.kebab_platforms.is_empty() {
                writeln!(out, "        platforms: crate::Platform::all(),")?;
            } else {
                let platforms = metadata
                    .kebab_platforms
                    .iter()
                    .map(|x| format!("Platform::{}", kebab_to_pascal(x)))
                    .join(" | ");
                writeln!(out, "        platforms: enum_set!{{ {platforms} }},")?;
            }

            let short_desc = json::stringify(metadata.short_desc())?;
            writeln!(out, "        short_desc: {short_desc},")?;

            let long_desc = json::stringify(&metadata.long_desc())?;
            writeln!(out, "        long_desc: {long_desc},")?;

            writeln!(out, "        verify_fn: _pkg_{snake_name}::verify,")?;
            writeln!(out, "        install_fn: _pkg_{snake_name}::install,")?;
            writeln!(out, "        uninstall_fn: _pkg_{snake_name}::uninstall,")?;

            if metadata.has_binary_dependencies {
                writeln!(
                    out,
                    "        binary_dependencies_fn: _pkg_{snake_name}::binary_dependencies,"
                )?;
            } else {
                writeln!(
                    out,
                    "        binary_dependencies_fn: _stub::empty_bin_dependencies,"
                )?;
            }
            if metadata.has_config_dependencies {
                writeln!(
                    out,
                    "        config_dependencies_fn: _pkg_{snake_name}::config_dependencies,"
                )?;
            } else {
                writeln!(
                    out,
                    "        config_dependencies_fn: _stub::empty_pkg_dependencies,"
                )?;
            }
            if metadata.has_download {
                writeln!(
                    out,
                    "        download_fn: |ctx| Box::pin(async move {{ _pkg_{snake_name}::download(ctx.as_ref()).await }}),"
                )?;
            } else {
                writeln!(out, "        download_fn: _stub::ok_future,")?;
            }
            if metadata.has_build {
                writeln!(out, "        build_fn: _pkg_{snake_name}::build,")?;
            } else {
                writeln!(out, "        build_fn: _stub::ok,")?;
            }
            if metadata.has_configure {
                writeln!(out, "        configure_fn: _pkg_{snake_name}::configure,")?;
            } else {
                writeln!(out, "        configure_fn: _stub::ok,")?;
            }
            if metadata.has_clean {
                writeln!(out, "        clean_fn: _pkg_{snake_name}::clean,")?;
            } else {
                writeln!(out, "        clean_fn: _stub::ok,")?;
            }

            writeln!(out, "    }},")?;
        }
        writeln!(out, "];")?;
        writeln!(out, "impl PkgId {{")?;
        writeln!(
            out,
            "    /// Get package metadata\n    pub fn package(self) -> &'static crate::Package {{ &METADATA_ARRAY[Enum::into_usize(self)] }}"
        )?;
        writeln!(out, "}}")?;
        writeln!(out, "impl BinId {{")?;
        writeln!(
            out,
            "    /// Get packages that provide this binary\n    pub fn providers(self) -> EnumSet<PkgId> {{"
        )?;
        writeln!(out, "        match self {{")?;
        for (pascal_bin, kebab_bin) in std::iter::zip(&pascal_bins, &kebab_bins) {
            let mut providers = BTreeSet::default();
            for (pascal_pkg, m) in std::iter::zip(&pascal_pkgs, &modules) {
                if m.kebab_binaries.contains(kebab_bin.as_str()) {
                    providers.insert(format!("PkgId::{pascal_pkg}"));
                }
            }
            writeln!(
                out,
                "            Self::{pascal_bin} => enum_set!{{ {} }},",
                providers.iter().join(" | ")
            )?;
        }
        writeln!(out, "        }}\n    }}\n}}")?;

        // declare package modules

        for (path, name) in std::iter::zip(self.modules.values(), &snake_pkgs) {
            let path = path.normalize()?;
            let path = path.try_to_rel_from(&self.registry_path);
            // relative path ensures the output is consistent throughout
            // build environments
            cu::ensure!(path.is_relative());
            let path = path.as_utf8()?;
            writeln!(out, "#[path = \"{path}\"] mod _pkg_{name};")?;
        }

        Ok(out)
    }
}

fn generate_id_enum(
    out: &mut String,
    prefix: &str,
    kebab_values: &[&String],
    pascal_values: &[String],
) -> cu::Result<()> {
    use std::fmt::Write as _;

    writeln!(out, "#[derive(EnumSetType, Enum)]")?;
    writeln!(out, "pub enum {prefix}Id {{")?;
    for name in pascal_values {
        writeln!(out, "    {name},")?;
    }
    writeln!(out, "}}")?;
    let upper_prefix = prefix.to_ascii_uppercase();
    writeln!(
        out,
        "static {upper_prefix}_NAMES: phf::Map<&'static str, {prefix}Id> = phf::phf_map! {{"
    )?;
    for (kebab, pascal) in std::iter::zip(kebab_values, pascal_values) {
        writeln!(out, "    \"{kebab}\" => {prefix}Id::{pascal},")?;
    }
    writeln!(out, "}};")?;
    writeln!(out, "impl {prefix}Id {{")?;
    writeln!(
        out,
        "    /// Convert kebab-case name to enum\n    pub fn from_str(name: &str) -> Option<Self> {{ {upper_prefix}_NAMES.get(name).copied() }}"
    )?;
    writeln!(
        out,
        "    /// Get kebab-case name\n    pub fn to_str(self) -> &'static str {{ match self {{"
    )?;
    for (kebab, pascal) in std::iter::zip(kebab_values, pascal_values) {
        writeln!(out, "            Self::{pascal} => \"{kebab}\",")?;
    }
    writeln!(out, "        }}\n    }}\n}}")?;

    Ok(())
}

fn generate_casings_from_kebab<T: AsRef<str>>(kebab_values: &[T]) -> (Vec<String>, Vec<String>) {
    let mut pascal = Vec::with_capacity(kebab_values.len());
    let mut snake = Vec::with_capacity(kebab_values.len());
    for name in kebab_values {
        let n = name.as_ref();
        pascal.push(kebab_to_pascal(n));
        snake.push(kebab_to_snake(n));
    }
    (pascal, snake)
}

fn is_kebab(s: &str) -> bool {
    s.chars()
        .all(|c| c.is_ascii_lowercase() || matches!(c, '0'..='9') || c == '-')
}

fn kebab_to_pascal(kebab: &str) -> String {
    let mut pascal = String::with_capacity(kebab.len());
    for part in kebab.split('-') {
        let Some(c) = part.chars().next() else {
            continue;
        };
        pascal.push(c.to_ascii_uppercase());
        pascal.push_str(&part[c.len_utf8()..]);
    }
    pascal
}
fn kebab_to_snake(kebab: &str) -> String {
    kebab.replace('-', "_")
}

struct GeneratedModule {
    doc: Vec<String>,
    kebab_binaries: BTreeSet<String>,
    kebab_platforms: BTreeSet<String>,
    has_binary_dependencies: bool,
    has_config_dependencies: bool,
    has_download: bool,
    has_build: bool,
    has_configure: bool,
    has_clean: bool,
}
impl GeneratedModule {
    pub fn try_from_path(path: &Path) -> cu::Result<Self> {
        let file_content = cu::fs::read_string(path)?;
        let file_syntax = cu::check!(
            syn::parse_file(&file_content),
            "fail to parse '{}'",
            path.display()
        )?;

        let mut doc = vec!["".to_string()];
        let mut binaries = BTreeSet::default();
        let mut platforms = BTreeSet::default();
        let mut has_binary_dependencies = false;
        let mut has_config_dependencies = false;
        let mut has_download = false;
        let mut has_build = false;
        let mut has_configure = false;
        let mut has_clean = false;

        for attr in file_syntax.attrs {
            if !attr.path().is_ident("doc") {
                continue;
            }
            let Ok(lit) = attr.meta.require_name_value() else {
                continue;
            };
            let syn::Expr::Lit(syn::ExprLit {
                lit: syn::Lit::Str(ref lit),
                ..
            }) = lit.value
            else {
                continue;
            };
            let doc_lit = lit.value();
            let doc_lit = doc_lit.trim();
            if doc_lit.is_empty() {
                if !doc.last().unwrap().is_empty() {
                    doc.push("".to_string());
                }
            } else {
                let last = doc.last_mut().unwrap();
                if !last.is_empty() && !last.ends_with(' ') {
                    last.push(' ');
                }
                last.push_str(doc_lit);
            }
        }

        for item in file_syntax.items {
            match item {
                syn::Item::Macro(item) => {
                    if item.mac.path.is_ident("metadata_binaries") {
                        let body = item.mac.parse_body::<MacroBody>()?;
                        for lit in body.items {
                            binaries.insert(lit.value());
                        }
                    }
                    if item.mac.path.is_ident("metadata_platforms") {
                        let body = item.mac.parse_body::<MacroBody>()?;
                        for lit in body.items {
                            platforms.insert(lit.value());
                        }
                    }
                }

                syn::Item::Fn(item) => {
                    let ident = item.sig.ident.to_string();
                    match ident.as_str() {
                        "binary_dependencies" => has_binary_dependencies = true,
                        "config_dependencies" => has_config_dependencies = true,
                        "download" => has_download = true,
                        "build" => has_build = true,
                        "configure" => has_configure = true,
                        "clean" => has_clean = true,
                        _ => {}
                    }
                }

                _ => {}
            }
        }

        Ok(Self {
            doc,
            kebab_binaries: binaries,
            kebab_platforms: platforms,
            has_binary_dependencies,
            has_config_dependencies,
            has_download,
            has_build,
            has_configure,
            has_clean,
        })
    }

    fn short_desc(&self) -> &str {
        match self.doc.first() {
            Some(x) => x,
            None => "",
        }
    }

    fn long_desc(&self) -> String {
        self.doc.iter().skip(1).join("\n\n")
    }
}

struct MacroBody {
    items: syn::punctuated::Punctuated<syn::LitStr, syn::Token![,]>,
}
impl syn::parse::Parse for MacroBody {
    fn parse(input: syn::parse::ParseStream) -> pm::Result<Self> {
        let items = syn::punctuated::Punctuated::parse_terminated(input)?;
        Ok(Self { items })
    }
}
